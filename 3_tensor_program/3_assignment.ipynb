{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一节：如何编写 TensorIR\n",
    "在本节中，让我们尝试根据高级指令（例如 Numpy 或 Torch）手动编写 TensorIR。首先，我们给出一个逐位相加函数的例子，来展示我们应该如何编写一个 TensorIR 函数。\n",
    "\n",
    "示例：逐位相加\n",
    "首先，让我们尝试使用 Numpy 编写一个逐位相加函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 16., 16., 16.],\n",
       "       [16., 16., 16., 16.],\n",
       "       [16., 16., 16., 16.],\n",
       "       [16., 16., 16., 16.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T\n",
    "import numpy as np\n",
    "import IPython\n",
    "\n",
    "# init data\n",
    "dtype = \"float32\"\n",
    "a = np.arange(16).reshape(4, 4).astype(dtype)\n",
    "b = np.arange(16, 0, -1).reshape(4, 4).astype(dtype)\n",
    "\n",
    "# numpy version\n",
    "c_np = a + b\n",
    "c_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们直接编写 TensorIR 之前，我们应该首先将高级计算抽象（例如，ndarray + ndarray）转换为低级 Python 实现（具有元素访问和操作的循环的标准）。\n",
    "\n",
    "值得注意的是，输出数组（或缓冲区）的初始值并不总是 0。我们需要在我们的实现中编写或初始化它，这对于归约运算符（例如 matmul 和 conv）很重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 16., 16., 16.],\n",
       "       [16., 16., 16., 16.],\n",
       "       [16., 16., 16., 16.],\n",
       "       [16., 16., 16., 16.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low-level numpy version\n",
    "def lnumpy_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      c[i, j] = a[i, j] + b[i, j]\n",
    "c_lnumpy = np.empty((4, 4), dtype=\"float32\")\n",
    "lnumpy_add(a, b, c_lnumpy)\n",
    "c_lnumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorIR version\n",
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer[(4, 4), \"float32\"],\n",
    "          B: T.Buffer[(4, 4), \"float32\"],\n",
    "          C: T.Buffer[(4, 4), \"float32\"]):\n",
    "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
    "    for i, j in T.grid(4, 4):\n",
    "      with T.block(\"C\"):\n",
    "        vi = T.axis.spatial(4, i)\n",
    "        vj = T.axis.spatial(4, j)\n",
    "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
    "\n",
    "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
    "a_tvm = tvm.nd.array(a)\n",
    "b_tvm = tvm.nd.array(b)\n",
    "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=\"float32\"))\n",
    "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
    "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里原本示例上给的元素dtype均为int64，然而运行时总会出现assertion error，改为float32后可以正常运行。在discussion中也有同学提到。\n",
    "\n",
    "到这里，我们就完成了 TensorIR 函数。请花点时间完成以下练习。\n",
    "\n",
    "练习 1：广播加法\n",
    "请编写一个 TensorIR 函数，将两个数组以广播的方式相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]], dtype=float32),\n",
       " array([4., 3., 2., 1.], dtype=float32),\n",
       " array([[ 4.,  4.,  4.,  4.],\n",
       "        [ 8.,  8.,  8.,  8.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [16., 16., 16., 16.]], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init data\n",
    "dtype = \"float32\"\n",
    "a = np.arange(16).reshape(4, 4).astype(dtype)\n",
    "b = np.arange(4, 0, -1).reshape(4).astype(dtype)\n",
    "# numpy version\n",
    "c_np = a + b\n",
    "a, b, c_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请完成以下 IRModule MyAdd 并运行代码以检查你的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer[(4, 4), \"float32\"],\n",
    "          B: T.Buffer[(4)   , \"float32\"],\n",
    "          C: T.Buffer[(4, 4), \"float32\"]):\n",
    "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
    "    # TODO\n",
    "    for i, j in T.grid(4, 4):\n",
    "      with T.block(\"C\"):\n",
    "        vi = T.axis.spatial(4, i)\n",
    "        vj = T.axis.spatial(4, j)\n",
    "        \n",
    "        C[i, j] = A[i, j] + B[j]\n",
    "\n",
    "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
    "a_tvm = tvm.nd.array(a)\n",
    "b_tvm = tvm.nd.array(b)\n",
    "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=\"float32\"))\n",
    "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
    "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习 2：二维卷积\n",
    "然后，让我们尝试做一些具有挑战性的事情：二维卷积。这是图像处理中的常见操作。\n",
    "\n",
    "这是使用 NCHW 布局的卷积的数学定义：\n",
    "\n",
    "$$\n",
    "Conv[b, k, i, j] = \\sum_{di, dj, q} A[b, q, strides * i + di, strides * j + dj] * W[k, q, di, dj],\n",
    "Conv[b,k,i,j]= \n",
    "di,dj,q\n",
    "∑\n",
    "​\n",
    " A[b,q,strides∗i+di,strides∗j+dj]∗W[k,q,di,dj],\n",
    "$$\n",
    "其中，A 是输入张量，W 是权重张量，b 是批次索引，k 是输出通道，i 和 j 是图像高度和宽度的索引，di 和 dj 是权重的索引，q 是输入通道，strides 是过滤器窗口的步幅。\n",
    "\n",
    "在练习中，我们选择了一个小而简单的情况，即 stride=1, padding=0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
       "          [16., 17., 18., 19., 20., 21., 22., 23.],\n",
       "          [24., 25., 26., 27., 28., 29., 30., 31.],\n",
       "          [32., 33., 34., 35., 36., 37., 38., 39.],\n",
       "          [40., 41., 42., 43., 44., 45., 46., 47.],\n",
       "          [48., 49., 50., 51., 52., 53., 54., 55.],\n",
       "          [56., 57., 58., 59., 60., 61., 62., 63.]]]], dtype=float32),\n",
       " (1, 1, 8, 8),\n",
       " array([[[[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.],\n",
       "          [ 6.,  7.,  8.]]],\n",
       " \n",
       " \n",
       "        [[[ 9., 10., 11.],\n",
       "          [12., 13., 14.],\n",
       "          [15., 16., 17.]]]], dtype=float32),\n",
       " (2, 1, 3, 3),\n",
       " array([[[[ 474.,  510.,  546.,  582.,  618.,  654.],\n",
       "          [ 762.,  798.,  834.,  870.,  906.,  942.],\n",
       "          [1050., 1086., 1122., 1158., 1194., 1230.],\n",
       "          [1338., 1374., 1410., 1446., 1482., 1518.],\n",
       "          [1626., 1662., 1698., 1734., 1770., 1806.],\n",
       "          [1914., 1950., 1986., 2022., 2058., 2094.]],\n",
       " \n",
       "         [[1203., 1320., 1437., 1554., 1671., 1788.],\n",
       "          [2139., 2256., 2373., 2490., 2607., 2724.],\n",
       "          [3075., 3192., 3309., 3426., 3543., 3660.],\n",
       "          [4011., 4128., 4245., 4362., 4479., 4596.],\n",
       "          [4947., 5064., 5181., 5298., 5415., 5532.],\n",
       "          [5883., 6000., 6117., 6234., 6351., 6468.]]]], dtype=float32),\n",
       " (1, 2, 6, 6))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
    "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
    "data = np.arange(N*CI*H*W).reshape(N, CI, H, W).astype(\"float32\")\n",
    "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K).astype(\"float32\")\n",
    "# torch version\n",
    "import torch\n",
    "data_torch = torch.Tensor(data)\n",
    "weight_torch = torch.Tensor(weight)\n",
    "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
    "conv_torch = conv_torch.numpy().astype(\"float32\")\n",
    "data, data.shape, weight, weight.shape, conv_torch, conv_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请完成以下 IRModule MyConv 并运行代码以检查您的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyConv:\n",
    "  @T.prim_func\n",
    "  def conv(Data:  T.Buffer[(1, 1, 8, 8), \"float32\"],\n",
    "           Weight:T.Buffer[(2, 1, 3, 3), \"float32\"],\n",
    "           Conv:  T.Buffer[(1, 2, 6, 6), \"float32\"]):\n",
    "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
    "    # TODO\n",
    "    strides = 1\n",
    "    padding = 0\n",
    "    for b, k, i, j, di, dj, q in T.grid(1, 2, 6, 6, 3, 3, 1):\n",
    "      with T.block(\"Conv\"):\n",
    "        v_b = T.axis.spatial(1 ,b)\n",
    "        v_k = T.axis.spatial(2, k)\n",
    "        v_i = T.axis.spatial(6, i)\n",
    "        v_j = T.axis.spatial(6, j)\n",
    "        \n",
    "        v_di = T.axis.reduce(3, di)\n",
    "        v_dj = T.axis.reduce(3, dj)\n",
    "        v_q  = T.axis.reduce(1, q)\n",
    "        # 注意此处，我们在b,k,i,j这个坐标上对di,dj,q三个归约轴求和。\n",
    "        # 实现上是通过循环来累加，因此需要对结果数组进行初始化\n",
    "        with T.init():\n",
    "          Conv[v_b, v_k, v_i, v_j] = T.float32(0)\n",
    "        Conv[v_b, v_k, v_i, v_j] += Data[v_b, v_q, strides*v_i+v_di, strides*v_j+v_dj] * Weight[v_k, v_q, v_di, v_dj]\n",
    "\n",
    "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
    "data_tvm = tvm.nd.array(data)\n",
    "weight_tvm = tvm.nd.array(weight)\n",
    "conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=\"float32\"))\n",
    "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
    "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二节：如何变换 TensorIR\n",
    "\n",
    "在讲座中，我们了解到 TensorIR 不仅是一种编程语言，而且还是一种程序变换的抽象。在本节中，让我们尝试变换程序。我们在采用了 bmm_relu (batched_matmul_relu)，这是一种常见于 Transformer 等模型中的操作变体。\n",
    "\n",
    "并行化、向量化与循环展开\n",
    "首先，我们介绍一些新的原语：parallel、vectorize 和 unroll。这三个原语被应用于循环上，指示循环应当如何执行。这是示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".highlight .hll { background-color: #ffffcc }\n",
       ".highlight { background: #f8f8f8; }\n",
       ".highlight .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".highlight .err { border: 1px solid #FF0000 } /* Error */\n",
       ".highlight .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".highlight .o { color: #666666 } /* Operator */\n",
       ".highlight .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".highlight .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".highlight .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".highlight .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".highlight .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".highlight .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".highlight .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".highlight .ge { font-style: italic } /* Generic.Emph */\n",
       ".highlight .gr { color: #E40000 } /* Generic.Error */\n",
       ".highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".highlight .gi { color: #008400 } /* Generic.Inserted */\n",
       ".highlight .go { color: #717171 } /* Generic.Output */\n",
       ".highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".highlight .gs { font-weight: bold } /* Generic.Strong */\n",
       ".highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".highlight .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".highlight .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".highlight .kt { color: #B00040 } /* Keyword.Type */\n",
       ".highlight .m { color: #666666 } /* Literal.Number */\n",
       ".highlight .s { color: #BA2121 } /* Literal.String */\n",
       ".highlight .na { color: #687822 } /* Name.Attribute */\n",
       ".highlight .nb { color: #008000 } /* Name.Builtin */\n",
       ".highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".highlight .no { color: #880000 } /* Name.Constant */\n",
       ".highlight .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".highlight .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".highlight .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".highlight .nf { color: #0000FF } /* Name.Function */\n",
       ".highlight .nl { color: #767600 } /* Name.Label */\n",
       ".highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".highlight .nv { color: #19177C } /* Name.Variable */\n",
       ".highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".highlight .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".highlight .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".highlight .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".highlight .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".highlight .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".highlight .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".highlight .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".highlight .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".highlight .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".highlight .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".highlight .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".highlight .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".highlight .sx { color: #008000 } /* Literal.String.Other */\n",
       ".highlight .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".highlight .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".highlight .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".highlight .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".highlight .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".highlight .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".highlight .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".highlight .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@tir</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">func</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">])</span> <span class=\"o\">-&gt;</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;add&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with tir.block(&quot;root&quot;)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i_0</span> <span class=\"ow\">in</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">for</span> <span class=\"n\">i_1</span> <span class=\"ow\">in</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">unroll</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n",
       "                <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">vectorized</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">):</span>\n",
       "                    <span class=\"k\">with</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
       "                        <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">i_0</span> <span class=\"o\">*</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">i_1</span><span class=\"p\">)</span>\n",
       "                        <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">)</span>\n",
       "                        <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "    \n",
       "</pre></div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def code2html(code):\n",
    "    \"\"\"Helper function to use pygments to turn the code string into highlighted html.\"\"\"\n",
    "    import pygments\n",
    "    from pygments.lexers import Python3Lexer\n",
    "    from pygments.formatters import HtmlFormatter\n",
    "    formatter = HtmlFormatter()\n",
    "    html = pygments.highlight(code, Python3Lexer(), formatter)\n",
    "    return \"<style>%s</style>%s\\n\" % (formatter.get_style_defs(\".highlight\"), html)\n",
    "\n",
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
    "          B: T.Buffer[(4, 4), \"int64\"],\n",
    "          C: T.Buffer[(4, 4), \"int64\"]):\n",
    "    T.func_attr({\"global_symbol\": \"add\"})\n",
    "    for i, j in T.grid(4, 4):\n",
    "      with T.block(\"C\"):\n",
    "        vi = T.axis.spatial(4, i)\n",
    "        vj = T.axis.spatial(4, j)\n",
    "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
    "\n",
    "sch = tvm.tir.Schedule(MyAdd)\n",
    "block = sch.get_block(\"C\", func_name=\"add\")\n",
    "i, j = sch.get_loops(block)\n",
    "i0, i1 = sch.split(i, factors=[2, 2])\n",
    "sch.parallel(i0)\n",
    "sch.unroll(i1)\n",
    "sch.vectorize(j)\n",
    "IPython.display.HTML(code2html(sch.mod.script()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel相当于把循环底下的执行部分做成了一个线程，提供线程级并行\n",
    "\n",
    "vectorize是SIMD，即使用一条指令操纵多条数据。\n",
    "\n",
    "unroll是循环展开（传统编译器常见优化），loop unroll是经典的提高IPC的方法之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习 3：变换批量矩阵乘法程序\n",
    "现在，让我们回到 bmm_relu 练习。首先，让我们看看 bmm 的定义：\n",
    "$$\n",
    "Y_{n, i, j} = \\sum_k A_{n, i, k} \\times B_{n, k, j}Y \n",
    "n,i,j\n",
    "​\n",
    " =∑ \n",
    "k\n",
    "​\n",
    " A \n",
    "n,i,k\n",
    "​\n",
    " ×B \n",
    "n,k,j\n",
    "​\n",
    " \\\\\n",
    "C_{n, i, j} = \\mathbb{relu}(Y_{n,i,j}) = \\mathbb{max}(Y_{n, i, j}, 0)C \n",
    "n,i,j\n",
    "​\n",
    " =relu(Y \n",
    "n,i,j\n",
    "​\n",
    " )=max(Y \n",
    "n,i,j\n",
    "​\n",
    " ,0)\n",
    " $$\n",
    "现在是你为 bmm_relu 编写 TensorIR 的时候了。我们提供 lnumpy 函数作为提示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
    "    Y = np.empty((16, 128, 128), dtype=\"float32\")\n",
    "    for n in range(16):\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                for k in range(128):\n",
    "                    if k == 0:\n",
    "                        Y[n, i, j] = 0\n",
    "                    Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
    "    for n in range(16):\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                C[n, i, j] = max(Y[n, i, j], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyBmmRelu:\n",
    "  @T.prim_func\n",
    "  def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], \n",
    "               B: T.Buffer[(16, 128, 128), \"float32\"], \n",
    "               C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
    "    T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
    "    # TODO\n",
    "    Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
    "    for n, i, j, k in T.grid(16, 128, 128, 128):\n",
    "      with T.block(\"Y\"):\n",
    "        v_n = T.axis.spatial(16,  n)\n",
    "        v_i = T.axis.spatial(128, i)\n",
    "        v_j = T.axis.spatial(128, j)\n",
    "        v_k = T.axis.reduce (128, k)\n",
    "\n",
    "        with T.init():\n",
    "          Y[v_n, v_i, v_j] = T.float32(0)\n",
    "        Y[v_n, v_i, v_j] += A[v_n, v_i, v_k] * B[v_n, v_k, v_j]\n",
    "\n",
    "    for n, i, j in T.grid(16, 128, 128):\n",
    "      with T.block(\"C\"):\n",
    "        v_n = T.axis.spatial(16,  n)\n",
    "        v_i = T.axis.spatial(128, i)\n",
    "        v_j = T.axis.spatial(128, j)\n",
    "\n",
    "        C[v_n, v_i, v_j] = T.max(T.float32(0), Y[v_n, v_i, v_j])\n",
    "\n",
    "\n",
    "sch = tvm.tir.Schedule(MyBmmRelu)\n",
    "IPython.display.HTML(code2html(sch.mod.script()))\n",
    "# Also please validate your result\n",
    "rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
    "A = np.ones(16*128*128).reshape(16, 128, 128).astype(\"float32\")\n",
    "B = np.ones(16*128*128).reshape(16, 128, 128).astype(\"float32\")\n",
    "C = np.empty((16, 128, 128), dtype=\"float32\")\n",
    "\n",
    "lnumpy_mm_relu_v2(A, B, C)\n",
    "\n",
    "A_tvm = tvm.nd.array(A)\n",
    "B_tvm = tvm.nd.array(B)\n",
    "C_tvm = tvm.nd.array(np.empty((16, 128, 128), dtype=\"float32\"))\n",
    "rt_lib[\"bmm_relu\"](A_tvm, B_tvm, C_tvm)\n",
    "# 注意tvm的array类型numpy无法识别，会报TypeError，因此要转成numpy类型才可以\n",
    "np.testing.assert_allclose(C, C_tvm.numpy(), rtol=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本练习中，让我们专注于将原始程序变换为特定目标。请注意，由于硬件不同，目标程序可能不是最好的程序。但是这个练习旨在让你了解如何将程序变换为想要的程序。 这是目标程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class TargetModule:\n",
    "    @T.prim_func\n",
    "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
    "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
    "        for i0 in T.parallel(16):\n",
    "            for i1, i2_0 in T.grid(128, 16):\n",
    "                for ax0_init in T.vectorized(8):\n",
    "                    with T.block(\"Y_init\"):\n",
    "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                        j = T.axis.spatial(128, i2_0 * 8 + ax0_init)\n",
    "                        Y[n, i, j] = T.float32(0)\n",
    "                for ax1_0 in T.serial(32):\n",
    "                    for ax1_1 in T.unroll(4):\n",
    "                        for ax0 in T.serial(8):\n",
    "                            with T.block(\"Y_update\"):\n",
    "                                n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                                j = T.axis.spatial(128, i2_0 * 8 + ax0)\n",
    "                                k = T.axis.reduce(128, ax1_0 * 4 + ax1_1)\n",
    "                                Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
    "                for i2_1 in T.vectorized(8):\n",
    "                    with T.block(\"C\"):\n",
    "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                        j = T.axis.spatial(128, i2_0 * 8 + i2_1)\n",
    "                        C[n, i, j] = T.max(Y[n, i, j], T.float32(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的任务是将原始程序转换为目标程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".highlight .hll { background-color: #ffffcc }\n",
       ".highlight { background: #f8f8f8; }\n",
       ".highlight .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".highlight .err { border: 1px solid #FF0000 } /* Error */\n",
       ".highlight .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".highlight .o { color: #666666 } /* Operator */\n",
       ".highlight .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".highlight .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".highlight .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".highlight .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".highlight .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".highlight .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".highlight .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".highlight .ge { font-style: italic } /* Generic.Emph */\n",
       ".highlight .gr { color: #E40000 } /* Generic.Error */\n",
       ".highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".highlight .gi { color: #008400 } /* Generic.Inserted */\n",
       ".highlight .go { color: #717171 } /* Generic.Output */\n",
       ".highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".highlight .gs { font-weight: bold } /* Generic.Strong */\n",
       ".highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".highlight .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".highlight .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".highlight .kt { color: #B00040 } /* Keyword.Type */\n",
       ".highlight .m { color: #666666 } /* Literal.Number */\n",
       ".highlight .s { color: #BA2121 } /* Literal.String */\n",
       ".highlight .na { color: #687822 } /* Name.Attribute */\n",
       ".highlight .nb { color: #008000 } /* Name.Builtin */\n",
       ".highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".highlight .no { color: #880000 } /* Name.Constant */\n",
       ".highlight .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".highlight .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".highlight .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".highlight .nf { color: #0000FF } /* Name.Function */\n",
       ".highlight .nl { color: #767600 } /* Name.Label */\n",
       ".highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".highlight .nv { color: #19177C } /* Name.Variable */\n",
       ".highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".highlight .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".highlight .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".highlight .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".highlight .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".highlight .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".highlight .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".highlight .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".highlight .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".highlight .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".highlight .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".highlight .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".highlight .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".highlight .sx { color: #008000 } /* Literal.String.Other */\n",
       ".highlight .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".highlight .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".highlight .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".highlight .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".highlight .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".highlight .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".highlight .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".highlight .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@tir</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">func</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">])</span> <span class=\"o\">-&gt;</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;bmm_relu&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with tir.block(&quot;root&quot;)</span>\n",
       "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"ow\">in</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">for</span> <span class=\"n\">j_1_init</span> <span class=\"ow\">in</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">serial</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y_init&quot;</span><span class=\"p\">):</span>\n",
       "                    <span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">v_j</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j_1_init</span><span class=\"p\">)</span>\n",
       "                    <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">()</span>\n",
       "                    <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "            <span class=\"k\">for</span> <span class=\"n\">k_0</span><span class=\"p\">,</span> <span class=\"n\">k_1</span><span class=\"p\">,</span> <span class=\"n\">j_1</span> <span class=\"ow\">in</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">):</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y_update&quot;</span><span class=\"p\">):</span>\n",
       "                    <span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">v_j</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j_1</span><span class=\"p\">)</span>\n",
       "                    <span class=\"n\">v_k</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">reduce</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">k_0</span> <span class=\"o\">*</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"n\">k_1</span><span class=\"p\">)</span>\n",
       "                    <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">],</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_k</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_k</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_k</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_k</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">]</span>\n",
       "            <span class=\"k\">for</span> <span class=\"n\">ax0</span> <span class=\"ow\">in</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">serial</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
       "                    <span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">v_j</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">ax0</span><span class=\"p\">)</span>\n",
       "                    <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">tir</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">v_n</span><span class=\"p\">,</span> <span class=\"n\">v_i</span><span class=\"p\">,</span> <span class=\"n\">v_j</span><span class=\"p\">])</span>\n",
       "    \n",
       "</pre></div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(MyBmmRelu)\n",
    "# TODO: transformations\n",
    "# Hints: you can use\n",
    "# `IPython.display.Code(sch.mod.script(), language=\"python\")`\n",
    "# or `print(sch.mod.script())`\n",
    "# to show the current program at any time during the transformation.\n",
    "\n",
    "# Step 1. Get blocks\n",
    "Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
    "C = sch.get_block(\"C\", func_name=\"bmm_relu\")\n",
    "\n",
    "# Step 2. Get loops\n",
    "n, i, j, k = sch.get_loops(Y)\n",
    "c_n, c_i, c_j = sch.get_loops(C)\n",
    "\n",
    "# Step 3. Organize the loops\n",
    "j_0, j_1 = sch.split(j, factors=[16, 8])\n",
    "k_0, k_1 = sch.split(k, factors=[32, 4])\n",
    "sch.reorder(n, i, j_0, k_0, k_1, j_1)\n",
    "IPython.display.HTML(code2html(sch.mod.script()))\n",
    "\n",
    "sch.reverse_compute_at(C, j_0)\n",
    "# ...\n",
    "# Step 4. decompose reduction\n",
    "Y_init = sch.decompose_reduction(Y, k_0)\n",
    "# ...\n",
    "IPython.display.HTML(code2html(sch.mod.script()))\n",
    "# # Step 5. vectorize / parallel / unroll\n",
    "# sch.vectorize(j_1)\n",
    "# sch.parallel(n)\n",
    "# sch.unroll(...)\n",
    "# ...\n",
    "\n",
    "# IPython.display.HTML(code2html(sch.mod.script()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（可选） 如果我们想确保变换后的程序与给定的目标完全相同，我们可以使用 assert_structural_equal。请注意，此步骤是本练习中的可选步骤。 如果您将程序朝着目标转变并获得性能提升，这就足够了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  File \"D:\\a\\utils\\utils\\tvm\\src\\node\\structural_equal.cc\", line 123\nValueError: StructuralEqual check failed, caused by lhs:\nfor (n: int32, 0, 16) {\n  for (i: int32, 0, 128) {\n    for (j_0: int32, 0, 16) {\n      for (j_1_init: int32, 0, 8) {\n        block([16, 128, 128], \"Y_init\") as [v_n, v_i, v_j] {\n          bind(v_n, n)\n          bind(v_i, i)\n          bind(v_j, ((j_0*8) + j_1_init))\n          tir.reads([])\n          tir.writes([Y: Buffer(Y_1: Pointer(global float32), float32, [16, 128, 128], [])[v_n, v_i, v_j]])\n          Y[v_n, v_i, v_j] = 0f32\n      }\n      for (k_0: int32, 0, 32) {\n        for (k_1: int32, 0, 4) {\n          for (j_1: int32, 0, 8) {\n            block([16, 128, 128, tir.reduce_axis(0, 128)], \"Y_update\") as [v_n_1, v_i_1, v_j_1, v_k] {\n              bind(v_n_1, n)\n              bind(v_i_1, i)\n              bind(v_j_1, ((j_0*8) + j_1))\n              bind(v_k, ((k_0*4) + k_1))\n              tir.reads([Y[v_n_1, v_i_1, v_j_1], A: Buffer(A_1: Pointer(global float32), float32, [16, 128, 128], [])[v_n_1, v_i_1, v_k], B: Buffer(B_1: Pointer(global float32), float32, [16, 128, 128], [])[v_n_1, v_k, v_j_1]])\n              tir.writes([Y[v_n_1, v_i_1, v_j_1]])\n              Y[v_n_1, v_i_1, v_j_1] = (Y[v_n_1, v_i_1, v_j_1] + (A[v_n_1, v_i_1, v_k]*B[v_n_1, v_k, v_j_1]))\n          }\n        }\n      }\n      for (ax0: int32, 0, 8) {\n        block([16, 128, 128], \"C\") as [v_n_2, v_i_2, v_j_2] {\n          bind(v_n_2, n)\n          bind(v_i_2, i)\n          bind(v_j_2, ((j_0*8) + ax0))\n          tir.reads([Y[v_n_2, v_i_2, v_j_2]])\n          tir.writes([C: Buffer(C_1: Pointer(global float32), float32, [16, 128, 128], [])[v_n_2, v_i_2, v_j_2]])\n          C[v_n_2, v_i_2, v_j_2] = max(0f32, Y[v_n_2, v_i_2, v_j_2])\n      }\n    }\n  }\n}\nand rhs:\nfor (i0: int32, 0, 16) \"parallel\" {\n  for (i1: int32, 0, 128) {\n    for (i2_0: int32, 0, 16) {\n      for (ax0_init: int32, 0, 8) \"vectorized\" {\n        block([16, 128, 128], \"Y_init\") as [n, i, j] {\n          bind(n, i0)\n          bind(i, i1)\n          bind(j, ((i2_0*8) + ax0_init))\n          tir.reads([])\n          tir.writes([Y: Buffer(Y_1: Pointer(global float32), float32, [16, 128, 128], [])[n, i, j]])\n          Y[n, i, j] = 0f32\n      }\n      for (ax1_0: int32, 0, 32) {\n        for (ax1_1: int32, 0, 4) \"unroll\" {\n          for (ax0: int32, 0, 8) {\n            block([16, 128, 128, tir.reduce_axis(0, 128)], \"Y_update\") as [n_1, i_1, j_1, k] {\n              bind(n_1, i0)\n              bind(i_1, i1)\n              bind(j_1, ((i2_0*8) + ax0))\n              bind(k, ((ax1_0*4) + ax1_1))\n              tir.reads([Y[n_1, i_1, j_1], A: Buffer(A_1: Pointer(global float32), float32, [16, 128, 128], [])[n_1, i_1, k], B: Buffer(B_1: Pointer(global float32), float32, [16, 128, 128], [])[n_1, k, j_1]])\n              tir.writes([Y[n_1, i_1, j_1]])\n              Y[n_1, i_1, j_1] = (Y[n_1, i_1, j_1] + (A[n_1, i_1, k]*B[n_1, k, j_1]))\n          }\n        }\n      }\n      for (i2_1: int32, 0, 8) \"vectorized\" {\n        block([16, 128, 128], \"C\") as [n_2, i_2, j_2] {\n          bind(n_2, i0)\n          bind(i_2, i1)\n          bind(j_2, ((i2_0*8) + i2_1))\n          tir.reads([Y[n_2, i_2, j_2]])\n          tir.writes([C: Buffer(C_1: Pointer(global float32), float32, [16, 128, 128], [])[n_2, i_2, j_2]])\n          C[n_2, i_2, j_2] = max(Y[n_2, i_2, j_2], 0f32)\n      }\n    }\n  }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18132\\819329240.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_structural_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTargetModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25966\\anaconda3\\envs\\mlc\\lib\\site-packages\\tvm\\ir\\base.py\u001b[0m in \u001b[0;36massert_structural_equal\u001b[1;34m(lhs, rhs, map_free_vars)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[0mlhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[0mrhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[0mtvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ffi_node_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStructuralEqual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_free_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25966\\anaconda3\\envs\\mlc\\lib\\site-packages\\tvm\\_ffi\\_ctypes\\packed_func.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         ):\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTVMError\u001b[0m: Traceback (most recent call last):\n  File \"D:\\a\\utils\\utils\\tvm\\src\\node\\structural_equal.cc\", line 123\nValueError: StructuralEqual check failed, caused by lhs:\nfor (n: int32, 0, 16) {\n  for (i: int32, 0, 128) {\n    for (j_0: int32, 0, 16) {\n      for (j_1_init: int32, 0, 8) {\n        block([16, 128, 128], \"Y_init\") as [v_n, v_i, v_j] {\n          bind(v_n, n)\n          bind(v_i, i)\n          bind(v_j, ((j_0*8) + j_1_init))\n          tir.reads([])\n          tir.writes([Y: Buffer(Y_1: Pointer(global float32), float32, [16, 128, 128], [])[v_n, v_i, v_j]])\n          Y[v_n, v_i, v_j] = 0f32\n      }\n      for (k_0: int32, 0, 32) {\n        for (k_1: int32, 0, 4) {\n          for (j_1: int32, 0, 8) {\n            block([16, 128, 128, tir.reduce_axis(0, 128)], \"Y_update\") as [v_n_1, v_i_1, v_j_1, v_k] {\n              bind(v_n_1, n)\n              bind(v_i_1, i)\n              bind(v_j_1, ((j_0*8) + j_1))\n              bind(v_k, ((k_0*4) + k_1))\n              tir.reads([Y[v_n_1, v_i_1, v_j_1], A: Buffer(A_1: Pointer(global float32), float32, [16, 128, 128], [])[v_n_1, v_i_1, v_k], B: Buffer(B_1: Pointer(global float32), float32, [16, 128, 128], [])[v_n_1, v_k, v_j_1]])\n              tir.writes([Y[v_n_1, v_i_1, v_j_1]])\n              Y[v_n_1, v_i_1, v_j_1] = (Y[v_n_1, v_i_1, v_j_1] + (A[v_n_1, v_i_1, v_k]*B[v_n_1, v_k, v_j_1]))\n          }\n        }\n      }\n      for (ax0: int32, 0, 8) {\n        block([16, 128, 128], \"C\") as [v_n_2, v_i_2, v_j_2] {\n          bind(v_n_2, n)\n          bind(v_i_2, i)\n          bind(v_j_2, ((j_0*8) + ax0))\n          tir.reads([Y[v_n_2, v_i_2, v_j_2]])\n          tir.writes([C: Buffer(C_1: Pointer(global float32), float32, [16, 128, 128], [])[v_n_2, v_i_2, v_j_2]])\n          C[v_n_2, v_i_2, v_j_2] = max(0f32, Y[v_n_2, v_i_2, v_j_2])\n      }\n    }\n  }\n}\nand rhs:\nfor (i0: int32, 0, 16) \"parallel\" {\n  for (i1: int32, 0, 128) {\n    for (i2_0: int32, 0, 16) {\n      for (ax0_init: int32, 0, 8) \"vectorized\" {\n        block([16, 128, 128], \"Y_init\") as [n, i, j] {\n          bind(n, i0)\n          bind(i, i1)\n          bind(j, ((i2_0*8) + ax0_init))\n          tir.reads([])\n          tir.writes([Y: Buffer(Y_1: Pointer(global float32), float32, [16, 128, 128], [])[n, i, j]])\n          Y[n, i, j] = 0f32\n      }\n      for (ax1_0: int32, 0, 32) {\n        for (ax1_1: int32, 0, 4) \"unroll\" {\n          for (ax0: int32, 0, 8) {\n            block([16, 128, 128, tir.reduce_axis(0, 128)], \"Y_update\") as [n_1, i_1, j_1, k] {\n              bind(n_1, i0)\n              bind(i_1, i1)\n              bind(j_1, ((i2_0*8) + ax0))\n              bind(k, ((ax1_0*4) + ax1_1))\n              tir.reads([Y[n_1, i_1, j_1], A: Buffer(A_1: Pointer(global float32), float32, [16, 128, 128], [])[n_1, i_1, k], B: Buffer(B_1: Pointer(global float32), float32, [16, 128, 128], [])[n_1, k, j_1]])\n              tir.writes([Y[n_1, i_1, j_1]])\n              Y[n_1, i_1, j_1] = (Y[n_1, i_1, j_1] + (A[n_1, i_1, k]*B[n_1, k, j_1]))\n          }\n        }\n      }\n      for (i2_1: int32, 0, 8) \"vectorized\" {\n        block([16, 128, 128], \"C\") as [n_2, i_2, j_2] {\n          bind(n_2, i0)\n          bind(i_2, i1)\n          bind(j_2, ((i2_0*8) + i2_1))\n          tir.reads([Y[n_2, i_2, j_2]])\n          tir.writes([C: Buffer(C_1: Pointer(global float32), float32, [16, 128, 128], [])[n_2, i_2, j_2]])\n          C[n_2, i_2, j_2] = max(Y[n_2, i_2, j_2], 0f32)\n      }\n    }\n  }\n}"
     ]
    }
   ],
   "source": [
    "tvm.ir.assert_structural_equal(sch.mod, TargetModule)\n",
    "print(\"Pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transformation:\n",
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "  20.4089      20.4089      20.4089      20.4089       0.0000   \n",
      "               \n",
      "After transformation:\n",
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "   2.4941       2.4941       2.4941       2.4941       0.0000   \n",
      "               \n"
     ]
    }
   ],
   "source": [
    "before_rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
    "after_rt_lib = tvm.build(sch.mod, target=\"llvm\")\n",
    "a_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "b_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "c_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "after_rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
    "before_timer = before_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
    "print(\"Before transformation:\")\n",
    "print(before_timer(a_tvm, b_tvm, c_tvm))\n",
    "\n",
    "f_timer = after_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
    "print(\"After transformation:\")\n",
    "print(f_timer(a_tvm, b_tvm, c_tvm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mlc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e6767c76516aa6983e5fbdff35c9a9526d1829e119c968ba336debfe182c067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
