{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 与机器学习框架的整合\n",
    "\n",
    "## 前言\n",
    "\n",
    "在过去的章节中，我们学习了机器学习编译的抽象和张量函数之间的变换。\n",
    "\n",
    "本章将讨论如何将机器学习模型从现有的机器学习框架引入 MLC 流程。\n",
    "\n",
    "## 准备工作\n",
    "\n",
    "首先，我们导入必要的依赖项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T, relax as R\n",
    "from tvm import relax\n",
    "import numpy as np\n",
    "\n",
    "# This is needed for deferring annotation parsing in TVMScript\n",
    "from __future__ import annotations\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import fx\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过 Builder 构造 IRModule\n",
    "\n",
    "在过去的章节中，我们一直在通过直接编写 TVMScript 来构建 IRModule。 随着模型变得越来越大，我们需要一种编程方式来构建 IRModule。在本节中，我们回顾一些支持该过程的工具。\n",
    "\n",
    "### 从张量表达式构造 TensorIR\n",
    "- 编写TVMScript来构建TensorIR\n",
    "- 通过张良表达式构建\n",
    "\n",
    "首先，我们回顾张量表达式 (tensor expression, TE) 这一领域特定语言来构建 TensorIR 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先创建一个 placeholder，它表示 TensorIR 函数的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = te.placeholder((128, 128), name=\"A\", dtype=\"float32\")\n",
    "B = te.placeholder((128, 128), name=\"B\", dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的每个输入和中间结果都表示为一个 `te.Tensor` 对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.te.tensor.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个 `te.Tensor` 都有一个 shape 字段和 dtype 字段，用于记录计算的 shape 和数据类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过一系列张量表达式来描述计算。这里的 `te.compute` 使用 `te.compute(output_shape, fcompute)` 这样的接口，该接口接收输入的尺寸以及计算的张量表达式。fcompute 函数描述了我们要如何计算给定索引的每个元素 `[i, j]` 的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`te_matmul` 函数接受一个 `te.Tensor` 类型的对象，并返回矩阵乘法结果。请注意我们是如何根据 A 和 B 的输入 shape 构造计算的。`te_matmul` 适用于具有不同输入 shape 的 A 和 B。**在构建输入输出的placeholder后确定维度。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_matmul(A: te.Tensor, B: te.Tensor) -> te.Tensor:\n",
    "    assert A.shape[1] == B.shape[0]\n",
    "    n = A.shape[0]\n",
    "    m = B.shape[1]\n",
    "    k = te.reduce_axis((0, A.shape[1]), name=\"k\")\n",
    "    return te.compute((n, m), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name=\"matmul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用 A 和 B 获得调用 `te_matmul` 的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = te_matmul(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要创建 TensorIR 函数，我们可以调用 `te.create_prim_func` 并传入输入和输出值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;30;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(A: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], B: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], matmul: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "    \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "    T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "    \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "    \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i0, i1, i2 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatmul\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "            i, j, k \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSR\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1, i2])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mreads(A[i, k], B[k, j])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mwrites(matmul[i, j])\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00minit():\n",
      "                matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m)\n",
      "            matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m matmul[i, j] \u001b[38;5;129;01m+\u001b[39;00m A[i, k] \u001b[38;5;129;01m*\u001b[39;00m B[k, j]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "te.create_prim_func([A, B, C]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以用类似的方式为 ReLU 计算创建张量表达式。在这里，我们写一个可以适用于具有任何维度数量和 shape 的 `te.Tensor` 的 `te_relu` 函数。\n",
    "\n",
    "tips: *i -> i可以是任意长度的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_relu(A: te.Tensor) -> te.Tensor:\n",
    "    return te.compute(A.shape, lambda *i: te.max(A(*i), 0), name=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们在两种不同的输入维度数量和 shape 上尝试 `te_relu`。 第一个 `X1` 的尺寸为 `(10,)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;30;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(X1: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[\u001b[38;5;28m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], relu: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[\u001b[38;5;28m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "    \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "    T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "    \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "    \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i0 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mserial(\u001b[38;5;28m10\u001b[39m):\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "            i0_1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mspatial(\u001b[38;5;28m10\u001b[39m, i0)\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mreads(X1[i0_1])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mwrites(relu[i0_1])\n",
      "            relu[i0_1] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mmax(X1[i0_1], T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X1 = te.placeholder((10,), name=\"X1\", dtype=\"float32\")\n",
    "Y1 = te_relu(X1)\n",
    "te.create_prim_func([X1, Y1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后是形状为 `(10, 20)` 的 `X2`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;30;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(X1: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m10\u001b[39m, \u001b[38;5;28m20\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], relu: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m10\u001b[39m, \u001b[38;5;28m20\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "    \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "    T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "    \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "    \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i0, i1 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m10\u001b[39m, \u001b[38;5;28m20\u001b[39m):\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "            i0_1, i1_1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mreads(X1[i0_1, i1_1])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mwrites(relu[i0_1, i1_1])\n",
      "            relu[i0_1, i1_1] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mmax(X1[i0_1, i1_1], T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X2 = te.placeholder((10, 20), name=\"X1\", dtype=\"float32\")\n",
    "Y2 = te_relu(X2)\n",
    "te.create_prim_func([X2, Y2]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`te` API 允许我们做的另一件事是组合操作并创建“融合 (fused)”算子。例如，我们可以将 matmul 的结果再次应用 relu。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = te_matmul(A, B)\n",
    "D = te_relu(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过只传递感兴趣的输入和输出值，跳过中间值来创建一个 TensorIR 函数。 这将导致 matmul 的结果被分配为 TensorIR 函数中的**临时空间**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;30;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(A: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], B: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], relu: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "    \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "    T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "    \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "    \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "    matmul \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00malloc_buffer([\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m], dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i0, i1, i2 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatmul\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "            i, j, k \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSR\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1, i2])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mreads(A[i, k], B[k, j])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mwrites(matmul[i, j])\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00minit():\n",
      "                matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m)\n",
      "            matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m matmul[i, j] \u001b[38;5;129;01m+\u001b[39;00m A[i, k] \u001b[38;5;129;01m*\u001b[39;00m B[k, j]\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i0, i1 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "            i0_1, i1_1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mreads(matmul[i0_1, i1_1])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mwrites(relu[i0_1, i1_1])\n",
      "            relu[i0_1, i1_1] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mmax(matmul[i0_1, i1_1], T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "te.create_prim_func([A, B, D]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以将中间结果 C 传递到参数列表中。在这种情况下，TensorIR 函数希望我们也从调用方传入 C。通常我们建议只传入输入和输出，这样我们就可以在里面进行更高级的融合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;30;03m# from tvm.script import tir as T\u001b[39;00m\n",
      "\u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(A: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], B: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], matmul: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], relu: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "    \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "    T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "    \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "    \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i0, i1, i2 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatmul\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "            i, j, k \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSR\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1, i2])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mreads(A[i, k], B[k, j])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mwrites(matmul[i, j])\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00minit():\n",
      "                matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m)\n",
      "            matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m matmul[i, j] \u001b[38;5;129;01m+\u001b[39;00m A[i, k] \u001b[38;5;129;01m*\u001b[39;00m B[k, j]\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i0, i1 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "            i0_1, i1_1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mreads(matmul[i0_1, i1_1])\n",
      "            T\u001b[38;5;129;01m.\u001b[39;00mwrites(relu[i0_1, i1_1])\n",
      "            relu[i0_1, i1_1] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mmax(matmul[i0_1, i1_1], T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "te.create_prim_func([A, B, C, D]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 BlockBuilder 构造 IRModule\n",
    "\n",
    "到目前为止，我们已经创建了一个 TensorIR 函数。 为了构建端到端的模型执行，我们还需要能够通过计算图连接多个 TensorIR 函数。\n",
    "\n",
    "让我们首先创建一个 block builder，它可以帮助我们逐步构建一个 `relax.Function`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = relax.Var(\"A\", (128, 128), relax.DynTensorType(2, \"float32\"))\n",
    "B = relax.Var(\"B\", (128, 128), relax.DynTensorType(2, \"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通过创建 block builder 和一系列元张量函数来构造 Relax 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;129m@tvm\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mscript\u001b[38;5;129;01m.\u001b[39;00mir_module\n",
      "\u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModule\u001b[39;00m:\n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mte_matmul\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], rxplaceholder_1: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], matmul: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte_matmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1, i2 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatmul\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                i, j, k \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSR\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1, i2])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[i, k], rxplaceholder_1[k, j])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(matmul[i, j])\n",
      "                \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00minit():\n",
      "                    matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m)\n",
      "                matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m matmul[i, j] \u001b[38;5;129;01m+\u001b[39;00m rxplaceholder[i, k] \u001b[38;5;129;01m*\u001b[39;00m rxplaceholder_1[k, j]\n",
      "    \n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mte_relu\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], relu: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte_relu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                i0_1, i1_1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[i0_1, i1_1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(relu[i0_1, i1_1])\n",
      "                relu[i0_1, i1_1] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mmax(rxplaceholder[i0_1, i1_1], T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m))\n",
      "    \n",
      "    \u001b[38;5;129m@R\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mfunction\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(A: Tensor((\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m), B: Tensor((\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m Tensor(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim \u001b[38;5;129;01m=\u001b[39;00m \u001b[38;5;28m2\u001b[39m):\n",
      "        \u001b[38;5;30;03m# block 0\u001b[39;00m\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mdataflow():\n",
      "            lv \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(te_matmul, (A, B), (\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            lv1 \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(te_relu, (lv,), (\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            gv: Tensor((\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m lv1\n",
      "            R\u001b[38;5;129;01m.\u001b[39;00moutput(gv)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m gv\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bb = relax.BlockBuilder()\n",
    "\n",
    "with bb.function(\"main\"):\n",
    "    with bb.dataflow():\n",
    "        C = bb.emit_te(te_matmul, A, B)\n",
    "        D = bb.emit_te(te_relu, C)\n",
    "        R = bb.emit_output(D)\n",
    "    bb.emit_func_output(R, params=[A, B])\n",
    "\n",
    "MyModule = bb.get()\n",
    "MyModule.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深入理解 BlockBuilder API\n",
    "\n",
    "现在让我们深入了解 BlockBuilder 的 API。将 BlockBuilder 代码和生成的 IRModule 并排放置会很有帮助。\n",
    "\n",
    "![](../img/integration_block_builder.png)\n",
    "\n",
    "BlockBuilder 带有与 Relax 函数中相应的作用域。例如，`bb.dataflow()` 创建一个 dataflow block，其中所有对 BlockBuilder 的调用都处在 dataflow block 的作用域中。**dataflow中的计算均没有side effect**。\n",
    "\n",
    "```python\n",
    "with bb.function(\"main\"):\n",
    "    with bb.dataflow():\n",
    "        # every emit call generates a variable inside a dataflow block.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个中间结果都是一个 `relax.Var`，对应一个存储计算结果的变量。 `DataflowVar` 表示该变量是 dataflow block（和计算图）内的中间步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relax.expr.DataflowVar"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(C, relax.Var)\n",
    "\n",
    "# isinstance() 与 type() 区别：\n",
    "# type() 不会认为子类是一种父类类型，不考虑继承关系。\n",
    "# isinstance() 会认为子类是一种父类类型，考虑继承关系。\n",
    "# 如果要判断两个类型是否相同推荐使用 isinstance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relax 函数中的每一行都是由 `emit_te` 调用生成的。 例如，\n",
    "\n",
    "```python\n",
    "lv = R.call_tir(te_matmul, (A, B), (128, 128), dtype=\"float32\")\n",
    "```\n",
    "\n",
    "是由如下代码所生成。\n",
    "\n",
    "```python\n",
    "C = bb.emit_te(te_matmul, A, B).\n",
    "```\n",
    "\n",
    "在幕后，`bb.emit_te` 做了以下事情：\n",
    "\n",
    "- 为 A 和 B 创建一个输入 `te.placeholder`，\n",
    "- 通过 `te_matmul` 函数运行它们。\n",
    "- 调用 `te.create_prim_func` 来创建一个 TensorIR 函数。\n",
    "- 通过 `call_tir` 生成对函数的调用。\n",
    "\n",
    "我们可以发现，上面 BlockBuilder 构造后的结果是一个有两个中间值的计算图，一个节点对应 `te_matmul` 操作，另一个节点对应 `te_relu`。\n",
    "\n",
    "我们可以通过 `bb.emit_output` 创建每个 dataflow block 的输出变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with bb.dataflow():\n",
    "    ...\n",
    "    R = bb.emit_output(D)\n",
    "```\n",
    "\n",
    "上面的代码标志着 `D` 是一个可以在 dataflow block 之外引用的变量。\n",
    "\n",
    "最后，函数输出由 `bb.emit_func_output` 标记。 我们只能在每个函数作用域内调用一次 `emit_func_output`。\n",
    "\n",
    "值得注意的是，我们可以在输出阶段指定函数的参数列表。 这样做在我们动态收集参数列表的情况下会有帮助。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with bb.function(\"main\"):\n",
    "    ...\n",
    "    # specify parameters in the end\n",
    "    bb.emit_func_output(R, params=[A, B])\n",
    "```\n",
    "\n",
    "或者，我们也可以在函数范围的开头指定参数列表。\n",
    "\n",
    "```python\n",
    "# specify parameters in the beginning.\n",
    "with bb.function(\"main\", params=[A, B]):\n",
    "    ...\n",
    "    bb.emit_func_output(R)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从 PyTorch 导入模型\n",
    "\n",
    "现在我们已经学习了以编程方式构建 IRModule 的工具。 让我们使用它们将机器学习模型从 PyTorch 导入成为 IRModule。\n",
    "\n",
    "大多数机器学习框架都带有计算图抽象，其中每个节点对应一个操作，边对应它们之间的依赖关系。 我们将采用 PyTorch 模型，获取 PyTorch 原生格式的计算图，并将其转换为 IRModule。\n",
    "\n",
    "让我们从在 PyTorch 中定义一个模型开始。 为了使示例保持一致，我们将使用 matmul + ReLU 示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(128, 128))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        x = torch.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建 TorchFX GraphModule\n",
    "\n",
    "我们使用 TorchFX 来表示来自 PyTorch 的模型的计算图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.fx.graph_module.GraphModule.__new__.<locals>.GraphModuleImpl"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "fx_module = fx.symbolic_trace(model)\n",
    "type(fx_module) # fx_module表示计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fx_module` 包含一个简单的计算图，可以打印成表格便于查看。我们的目标是**将此图转换为 IRModule**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name    target                                                     args         kwargs\n",
      "-------------  ------  ---------------------------------------------------------  -----------  --------\n",
      "placeholder    x       x                                                          ()           {}\n",
      "get_attr       weight  weight                                                     ()           {}\n",
      "call_function  matmul  <built-in method matmul of type object at 0x7fdd897759a0>  (x, weight)  {}\n",
      "call_function  relu    <built-in method relu of type object at 0x7fdd897759a0>    (matmul,)    {}\n",
      "output         output  output                                                     (relu,)      {}\n"
     ]
    }
   ],
   "source": [
    "fx_module.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造映射函数\n",
    "\n",
    "让我们定义整体的翻译逻辑。 主要流程如下：\n",
    "\n",
    "- 创建一个 `node_map`，将 `fx.Node` 映射到相应的 `relax.Var`，该 `relax.Var` 代表 IRModule 中的已翻译节点。\n",
    "- 以拓扑顺序迭代 FX 图中的节点。\n",
    "- 给定映射输入，获取节点的映射输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_param(param: nn.Parameter):\n",
    "    ndim = len(param.data.shape)\n",
    "    # 把nn.Parameter参数映射到常数里\n",
    "    return relax.const(\n",
    "        param.data.cpu().numpy(), relax.DynTensorType(ndim, \"float32\")\n",
    "    )\n",
    "\n",
    "def fetch_attr(fx_mod, target: str):\n",
    "    \"\"\"Helper function to fetch an attr\"\"\"\n",
    "    target_atoms = target.split('.')\n",
    "    attr_itr = fx_mod\n",
    "    for i, atom in enumerate(target_atoms):\n",
    "        if not hasattr(attr_itr, atom):\n",
    "            raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "        attr_itr = getattr(attr_itr, atom)\n",
    "    return attr_itr\n",
    "\n",
    "# 将给定的fx module计算图转化为对应的ir module计算图\n",
    "def from_fx(fx_mod, input_shapes, call_function_map, call_module_map):\n",
    "    input_index = 0\n",
    "    node_map = {}\n",
    "    named_modules = dict(fx_mod.named_modules())\n",
    "\n",
    "    bb = relax.BlockBuilder()\n",
    "\n",
    "    fn_inputs = []\n",
    "    fn_output = None\n",
    "    with bb.function(\"main\"):\n",
    "        with bb.dataflow():\n",
    "            # 迭代计算图中节点（拓扑排序后）进行变换\n",
    "            for node in fx_mod.graph.nodes:\n",
    "                if node.op == \"placeholder\": # input\n",
    "                    # create input placeholder\n",
    "                    shape = input_shapes[input_index]\n",
    "                    input_index += 1\n",
    "                    input_var = relax.Var(\n",
    "                        node.target, shape, relax.DynTensorType(len(shape), \"float32\")\n",
    "                    )\n",
    "                    fn_inputs.append(input_var)\n",
    "                    node_map[node] = input_var\n",
    "                elif node.op == \"get_attr\": # fx_mod.weight -> \n",
    "                    node_map[node] = map_param(fetch_attr(fx_mod, node.target))\n",
    "                elif node.op == \"call_function\":\n",
    "                    node_map[node] = call_function_map[node.target](bb, node_map, node)\n",
    "                elif node.op == \"call_module\":\n",
    "                    named_module = named_modules[node.target]\n",
    "                    node_map[node] = call_module_map[type(named_module)](bb, node_map, node, named_module)\n",
    "                elif node.op == \"output\":\n",
    "                    output = node_map[node.args[0]]\n",
    "                    assert fn_output is None\n",
    "                    fn_output = bb.emit_output(output)\n",
    "        # output and finalize the function\n",
    "        bb.emit_func_output(output, fn_inputs)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们没有在 `from_fx` 函数中定义函数映射。 我们将通过映射提供每个 torch function 的翻译规则。 具体来说，以下代码块显示了我们如何通过 `emit_te` API 做到这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;129m@tvm\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mscript\u001b[38;5;129;01m.\u001b[39;00mir_module\n",
      "\u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModule\u001b[39;00m:\n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mte_matmul\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], rxplaceholder_1: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], matmul: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte_matmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1, i2 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatmul\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                i, j, k \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSR\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1, i2])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[i, k], rxplaceholder_1[k, j])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(matmul[i, j])\n",
      "                \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00minit():\n",
      "                    matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m)\n",
      "                matmul[i, j] \u001b[38;5;129;01m=\u001b[39;00m matmul[i, j] \u001b[38;5;129;01m+\u001b[39;00m rxplaceholder[i, k] \u001b[38;5;129;01m*\u001b[39;00m rxplaceholder_1[k, j]\n",
      "    \n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mte_relu\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], relu: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte_relu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                i0_1, i1_1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[i0_1, i1_1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(relu[i0_1, i1_1])\n",
      "                relu[i0_1, i1_1] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mmax(rxplaceholder[i0_1, i1_1], T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m))\n",
      "    \n",
      "    \u001b[38;5;129m@R\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mfunction\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(x: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m Tensor(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim \u001b[38;5;129;01m=\u001b[39;00m \u001b[38;5;28m2\u001b[39m):\n",
      "        \u001b[38;5;30;03m# block 0\u001b[39;00m\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mdataflow():\n",
      "            lv \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(te_matmul, (x, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m0\u001b[39m]), (\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            lv1 \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(te_relu, (lv,), (\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            gv: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m lv1\n",
      "            R\u001b[38;5;129;01m.\u001b[39;00moutput(gv)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m lv1\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_matmul(bb, node_map, node: fx.Node):\n",
    "    A = node_map[node.args[0]]\n",
    "    B = node_map[node.args[1]]\n",
    "    return bb.emit_te(te_matmul, A, B) # 返回生成的tensor expression\n",
    "\n",
    "def map_relu(bb, node_map, node: fx.Node):\n",
    "    A = node_map[node.args[0]]\n",
    "    return bb.emit_te(te_relu, A)\n",
    "\n",
    "MyModule = from_fx(\n",
    "    fx_module,\n",
    "    input_shapes = [(1, 128)],\n",
    "    call_function_map = { # 指定映射\n",
    "      torch.matmul: map_matmul,\n",
    "      torch.relu: map_relu,\n",
    "    },\n",
    "    call_module_map={},\n",
    ")\n",
    "\n",
    "MyModule.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回到 FashionMNIST 的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "img, label = next(iter(test_loader))\n",
    "img = img.reshape(1, 28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"Class:\", class_names[label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-19 17:24:02--  https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl [following]\n",
      "--2022-08-19 17:24:03--  https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 0.0.0.0, ::\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|0.0.0.0|:443... failed: Connection refused.\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|::|:443... failed: Connection refused.\n"
     ]
    }
   ],
   "source": [
    "# Hide outputs\n",
    "!wget -nc https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上是我们关心的模型，我们可以按如下的方式构建其 PyTorch 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear0 = nn.Linear(784, 128, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(128, 10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "mlp_model = MLP()\n",
    "\n",
    "mlp_params = pkl.load(open(\"fasionmnist_mlp_params.pkl\", \"rb\"))\n",
    "mlp_model.linear0.weight.data = torch.from_numpy(mlp_params[\"w0\"])\n",
    "mlp_model.linear0.bias.data = torch.from_numpy(mlp_params[\"b0\"])\n",
    "mlp_model.linear1.weight.data = torch.from_numpy(mlp_params[\"w1\"])\n",
    "mlp_model.linear1.bias.data = torch.from_numpy(mlp_params[\"b1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "torch_res = mlp_model(torch.from_numpy(img.reshape(1, 784)))\n",
    "\n",
    "pred_kind = np.argmax(torch_res.detach().numpy(), axis=1)\n",
    "print(\"Torch Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们尝试通过为相应的 `nn.Module` 定义映射函数来从 FX 转换。 在这里，我们重用了来自 TVM TOPI (TVM operator inventory) 的预定义 TE 库，而不是定义我们自己的张量表达式。\n",
    "\n",
    "- `topi.nn.dense(x, w)` 执行转置矩阵乘法`x @ w.T`\n",
    "- `topi.add` 执行广播加法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;129m@tvm\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mscript\u001b[38;5;129;01m.\u001b[39;00mir_module\n",
      "\u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModule\u001b[39;00m:\n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mte_relu\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], relu: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte_relu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                i0_1, i1_1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[i0_1, i1_1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(relu[i0_1, i1_1])\n",
      "                relu[i0_1, i1_1] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mmax(rxplaceholder[i0_1, i1_1], T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m))\n",
      "    \n",
      "    \u001b[38;5;129m@R\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mfunction\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(x: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m784\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m Tensor(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim \u001b[38;5;129;01m=\u001b[39;00m \u001b[38;5;28m2\u001b[39m):\n",
      "        \u001b[38;5;30;03m# block 0\u001b[39;00m\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mdataflow():\n",
      "            lv \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(dense, (x, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m0\u001b[39m]), (\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            lv1 \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(add, (lv, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m1\u001b[39m]), (\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            lv2 \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(te_relu, (lv1,), (\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            lv3 \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(dense1, (lv2, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m2\u001b[39m]), (\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            lv4 \u001b[38;5;129;01m=\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mcall_tir(add1, (lv3, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m3\u001b[39m]), (\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), dtype\u001b[38;5;129;01m=\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "            gv: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m lv4\n",
      "            R\u001b[38;5;129;01m.\u001b[39;00moutput(gv)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m lv4\n",
      "    \n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdense\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m784\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], rxplaceholder_1: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m784\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], T_matmul_NT: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout_free_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28m1\u001b[39m]})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1, i2 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m, \u001b[38;5;28m784\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT_matmul_NT\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                i, j, k \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSR\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1, i2])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[i, k], rxplaceholder_1[j, k])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(T_matmul_NT[i, j])\n",
      "                \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00minit():\n",
      "                    T_matmul_NT[i, j] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m)\n",
      "                T_matmul_NT[i, j] \u001b[38;5;129;01m=\u001b[39;00m T_matmul_NT[i, j] \u001b[38;5;129;01m+\u001b[39;00m rxplaceholder[i, k] \u001b[38;5;129;01m*\u001b[39;00m rxplaceholder_1[j, k]\n",
      "    \n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdense1\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], rxplaceholder_1: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m10\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], T_matmul_NT: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout_free_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28m1\u001b[39m]})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1, i2 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT_matmul_NT\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                i, j, k \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSR\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1, i2])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[i, k], rxplaceholder_1[j, k])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(T_matmul_NT[i, j])\n",
      "                \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00minit():\n",
      "                    T_matmul_NT[i, j] \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m0\u001b[39m)\n",
      "                T_matmul_NT[i, j] \u001b[38;5;129;01m=\u001b[39;00m T_matmul_NT[i, j] \u001b[38;5;129;01m+\u001b[39;00m rxplaceholder[i, k] \u001b[38;5;129;01m*\u001b[39;00m rxplaceholder_1[j, k]\n",
      "    \n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], rxplaceholder_1: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[\u001b[38;5;28m128\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], T_add: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT_add\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                ax0, ax1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[ax0, ax1], rxplaceholder_1[ax1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(T_add[ax0, ax1])\n",
      "                T_add[ax0, ax1] \u001b[38;5;129;01m=\u001b[39;00m rxplaceholder[ax0, ax1] \u001b[38;5;129;01m+\u001b[39;00m rxplaceholder_1[ax1]\n",
      "    \n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd1\u001b[39m(rxplaceholder: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], rxplaceholder_1: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[\u001b[38;5;28m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], T_add: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i0, i1 \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mgrid(\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT_add\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                ax0, ax1 \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mremap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i0, i1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(rxplaceholder[ax0, ax1], rxplaceholder_1[ax1])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(T_add[ax0, ax1])\n",
      "                T_add[ax0, ax1] \u001b[38;5;129;01m=\u001b[39;00m rxplaceholder[ax0, ax1] \u001b[38;5;129;01m+\u001b[39;00m rxplaceholder_1[ax1]\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tvm import topi\n",
    "\n",
    "def map_nn_linear(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]   # input\n",
    "    w = map_param(nn_mod.weight) # weight\n",
    "    if nn_mod.bias is not None:\n",
    "        b = map_param(nn_mod.bias) # bias\n",
    "    y = bb.emit_te(topi.nn.dense, x, w)\n",
    "    return bb.emit_te(topi.add, y, b)\n",
    "\n",
    "def map_nn_relu(bb, node_map, node, nn_mod):\n",
    "    return map_relu(bb, node_map, node)\n",
    "\n",
    "\n",
    "MLPModule = from_fx(\n",
    "    fx.symbolic_trace(mlp_model),\n",
    "    input_shapes = [(1, 784)],\n",
    "    call_function_map={\n",
    "    },\n",
    "    call_module_map={\n",
    "        torch.nn.Linear: map_nn_linear,\n",
    "        torch.nn.ReLU: map_nn_relu,\n",
    "    },\n",
    ")\n",
    "\n",
    "MLPModule.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModule Prediction: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "ex = relax.vm.build(MLPModule, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MLPModule Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 备注：翻译成高层算子\n",
    "\n",
    "在大多数机器学习框架中，有时先转换为更高一级的内置的原始算子会更有帮助。下面的代码块给出了一个例子来做到这一点。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;129m@tvm\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mscript\u001b[38;5;129;01m.\u001b[39;00mir_module\n",
      "\u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModule\u001b[39;00m:\n",
      "    \u001b[38;5;129m@R\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mfunction\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(x: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m784\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m Tensor(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim \u001b[38;5;129;01m=\u001b[39;00m \u001b[38;5;28m2\u001b[39m):\n",
      "        \u001b[38;5;30;03m# block 0\u001b[39;00m\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m R\u001b[38;5;129;01m.\u001b[39;00mdataflow():\n",
      "            lv: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m relax\u001b[38;5;129;01m.\u001b[39;00mnn\u001b[38;5;129;01m.\u001b[39;00mdense(x, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m0\u001b[39m])\n",
      "            lv1: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m relax\u001b[38;5;129;01m.\u001b[39;00madd(lv, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m1\u001b[39m])\n",
      "            lv2: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m128\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m relax\u001b[38;5;129;01m.\u001b[39;00mnn\u001b[38;5;129;01m.\u001b[39;00mrelu(lv1)\n",
      "            lv3: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m relax\u001b[38;5;129;01m.\u001b[39;00mnn\u001b[38;5;129;01m.\u001b[39;00mdense(lv2, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m2\u001b[39m])\n",
      "            lv4: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m relax\u001b[38;5;129;01m.\u001b[39;00madd(lv3, meta[relay\u001b[38;5;129;01m.\u001b[39;00mConstant][\u001b[38;5;28m3\u001b[39m])\n",
      "            gv: Tensor((\u001b[38;5;28m1\u001b[39m, \u001b[38;5;28m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01m=\u001b[39;00m lv4\n",
      "            R\u001b[38;5;129;01m.\u001b[39;00moutput(gv)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m lv4\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_nn_relu_op(bb, node_map, node, nn_mod):\n",
    "    A = node_map[node.args[0]]\n",
    "    return bb.emit(relax.op.relu(A))\n",
    "\n",
    "def map_nn_linear_op(bb, node_map, node, nn_mod):\n",
    "    x = node_map[node.args[0]]\n",
    "    w = map_param(nn_mod.weight)\n",
    "    if nn_mod.bias is not None:\n",
    "        b = map_param(nn_mod.bias)\n",
    "    y = bb.emit(relax.op.dense(x, w))\n",
    "    return bb.emit(relax.op.add(y, b))\n",
    "\n",
    "MLPModuleHighLevel = from_fx(\n",
    "    fx.symbolic_trace(mlp_model),\n",
    "    input_shapes = [(1, 784)],\n",
    "    call_function_map={\n",
    "    },\n",
    "    call_module_map={\n",
    "        torch.nn.Linear: map_nn_linear_op,\n",
    "        torch.nn.ReLU: map_nn_relu_op,\n",
    "    },\n",
    ")\n",
    "\n",
    "MLPModuleHighLevel.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面展示了我们使用那些内置的算子将模型导入为 IRModule 后的结果。这些内置算子是 **比 TensorIR 函数更高级别的抽象**。我们可以有不同的机会将这些原始算子进一步转换为库函数或 TensorIR 函数。\n",
    "\n",
    "在大多数情况下，在有高级算子支持的情况下，转换为高级内置函数会很有帮助。但是，有很多情况下我们找不到对应的高级内置算子或者想直接指定 TensorIR 函数。 在这些情况下，我们可以自定义翻译逻辑或变换从而生成 `call_tir` 或调用库函数。 通常，我们可以结合高级操作、TensorIR 和库抽象来获得最佳结果。 我们将在后续章节中讨论权衡取舍。\n",
    "\n",
    "## 讨论\n",
    "\n",
    "在本章中，我们重点关注了 MLC 流程的 **开发** 部分。 我们研究了从机器学习框架中获取模型到 IRModule 的不同方法。 我们还简要介绍了高级原始运算符。\n",
    "\n",
    "一旦我们将模型放入 IRModule 中，我们就可以在原始函数和计算图函数上引入更多种类的变换。一个好的 MLC 流程将这些转换组合在一起，形成最终部署形式。\n",
    "\n",
    "![](../img/mlc_process.png)\n",
    "\n",
    "## 总结\n",
    "\n",
    "- 张量表达式 API 允许我们创建原始的 TensorIR 函数。\n",
    "- BlockBuilder API 通过 `emit_te` 和其他函数创建 IRModule。\n",
    "- 通过将模型转换为 IRModule，实现与现有的机器学习框架的整合。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "112f2400822ae511bbb04110fbb03a33a7733e1b8a027d7811767108b2f677cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
